{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7cc7b9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1ac9523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata = {}\n",
    "models = ['DSChat', 'DSReason', 'GeminiFlash', 'o3', 'o3Batch', 'Qwen1', 'Qwen14', 'Qwen70']\n",
    "tests = ['Math', 'Logic']\n",
    "humanbruteforcemath = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 1, 10: 0, 11: 0, 12: 1, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0, 21: 0, 22: 0, 23: 0, 24: 0, 25: 0, 26: 0, 27: 1, 28: 0, 29: 0, 30: 0, 31: 0, 32: 1, 33: 0, 34: 0, 35: 0, 36: 0, 37: 0, 38: 1, 39: 0, 40: 0, 41: 0, 42: 0, 43: 1, 44: 1, 45: 1, 46: 1, 47: 0, 48: 0, 49: 0, 50: 0, 51: 0, 52: 0, 53: 0, 54: 1, 55: 1, 56: 0, 57: 0, 58: 0, 59: 0, 60: 0, 61: 0, 62: 0, 63: 1, 64: 0, 65: 0, 66: 0, 67: 0, 68: 0, 69: 0, 70: 0, 71: 0, 72: 1, 73: 0, 74: 0, 75: 0, 76: 0, 77: 0, 78: 0, 79: 0, 80: 0, 81: 1, 82: 0, 83: 0, 84: 0, 85: 0, 86: 0, 87: 0, 88: 0, 89: 0, 90: 0, 91: 0, 92: 1, 93: 0, 94: 0, 95: 0, 96: 0, 97: 1, 98: 0, 99: 0, 100: 0, 101: 0, 102: 0, 103: 1, 104: 1, 105: 0, 106: 0, 107: 1, 108: 0, 109: 0, 110: 0, 111: 0, 112: 0, 113: 0, 114: 0, 115: 0, 116: 0, 117: 0, 118: 0, 119: 0, 120: 0, 121: 0, 122: 0, 123: 0, 124: 0, 125: 0, 126: 0, 127: 0, 128: 0, 129: 1, 130: 0, 131: 0, 132: 1, 133: 1, 134: 0, 135: 1, 136: 0, 137: 0, 138: 0, 139: 0, 140: 0, 141: 0, 142: 0, 143: 0, 144: 0, 145: 0, 146: 0, 147: 0, 148: 0, 149: 0, 150: 1, 151: 0, 152: 0, 153: 0, 154: 1, 155: 0, 156: 0, 157: 0, 158: 0, 159: 0, 160: 0, 161: 0, 162: 0, 163: 0, 164: 0, 165: 0, 166: 0, 167: 0, 168: 0, 169: 0, 170: 1, 171: 0, 172: 0, 173: 1, 174: 0, 175: 0, 176: 0, 177: 0, 178: 0, 179: 0, 180: 0, 181: 0, 182: 0, 183: 0, 184: 1, 185: 0, 186: 1, 187: 0, 188: 0, 189: 0, 190: 0, 191: 0, 192: 0, 193: 0, 194: 0, 195: 0, 196: 1, 197: 0, 198: 0, 199: 0, 200: 0, 201: 0, 202: 0, 203: 0, 204: 0, 205: 0, 206: 0, 207: 1, 208: 0, 209: 0, 210: 0, 211: 0, 212: 0, 213: 0, 214: 0, 215: 0, 216: 0, 217: 0, 218: 0, 219: 0, 220: 0, 221: 0, 222: 0, 223: 0, 224: 0, 225: 1, 226: 0, 227: 0, 228: 0, 229: 0, 230: 0, 231: 0, 232: 0, 233: 0, 234: 0, 235: 0, 236: 0, 237: 0, 238: 0, 239: 0, 240: 0, 241: 0, 242: 0, 243: 0, 244: 0, 245: 0, 246: 1, 247: 0, 248: 0, 249: 0}\n",
    "humanbruteforcelogic = {0: 0, 1: 0, 2: 0, 3: 1, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 1, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 1, 20: 0, 21: 0, 22: 0, 23: 0, 24: 0, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0, 30: 0, 31: 0, 32: 0, 33: 1, 34: 0, 35: 0, 36: 0, 37: 0, 38: 0, 39: 1, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 0, 48: 0, 49: 0, 50: 1, 51: 0, 52: 1, 53: 0, 54: 0, 55: 0, 56: 0, 57: 0, 58: 1, 59: 0, 60: 0, 61: 0, 62: 0, 63: 1, 64: 1, 65: 0, 66: 0, 67: 0, 68: 0, 69: 0, 70: 0, 71: 0, 72: 1, 73: 0, 74: 0, 75: 0, 76: 0, 77: 0, 78: 0, 79: 0, 80: 0, 81: 0, 82: 0, 83: 0, 84: 0, 85: 0, 86: 0, 87: 0, 88: 0, 89: 0, 90: 0, 91: 0, 92: 0, 93: 0, 94: 0, 95: 0, 96: 1, 97: 0, 98: 0, 99: 0, 100: 0, 101: 0, 102: 0, 103: 0, 104: 1, 105: 0, 106: 0, 107: 1, 108: 0, 109: 1, 110: 0, 111: 0, 112: 0, 113: 0, 114: 0, 115: 0, 116: 0, 117: 0, 118: 0, 119: 0, 120: 0, 121: 0, 122: 0, 123: 1, 124: 0, 125: 0, 126: 0, 127: 1, 128: 0, 129: 0, 130: 0, 131: 0, 132: 0, 133: 0, 134: 0, 135: 0, 136: 0, 137: 0, 138: 0, 139: 0, 140: 0, 141: 0, 142: 0, 143: 0, 144: 0, 145: 0, 146: 0, 147: 0, 148: 0, 149: 0, 150: 0, 151: 0, 152: 0, 153: 0, 154: 0, 155: 0, 156: 0, 157: 0, 158: 0, 159: 0, 160: 0, 161: 0, 162: 0, 163: 0, 164: 0, 165: 0, 166: 0, 167: 0, 168: 0, 169: 0, 170: 0, 171: 0, 172: 0, 173: 0, 174: 0, 175: 0, 176: 1, 177: 0, 178: 0, 179: 0, 180: 0, 181: 0, 182: 0, 183: 0, 184: 0, 185: 0, 186: 0, 187: 1, 188: 0, 189: 0, 190: 0, 191: 0, 192: 0, 193: 1, 194: 0, 195: 0, 196: 0, 197: 0, 198: 0, 199: 0, 200: 0, 201: 0, 202: 0, 203: 0, 204: 1, 205: 0, 206: 0, 207: 0, 208: 0, 209: 0, 210: 0, 211: 1, 212: 0, 213: 0, 214: 0, 215: 0, 216: 0, 217: 0, 218: 0, 219: 0, 220: 0, 221: 0, 222: 1, 223: 0, 224: 0, 225: 0, 226: 0, 227: 1, 228: 0, 229: 0, 230: 0, 231: 0, 232: 0, 233: 0, 234: 0, 235: 0, 236: 0, 237: 0, 238: 0, 239: 0, 240: 0, 241: 0, 242: 0, 243: 0, 244: 1, 245: 0, 246: 0, 247: 0, 248: 0, 249: 0}\n",
    "mathdifficulty = {}\n",
    "logicdifficulty = {}\n",
    "mathpopularity = {}\n",
    "logicpopularity = {}\n",
    "mathcategory = {}\n",
    "logiccategory = {}\n",
    "\n",
    "logicdata = pd.read_csv(\"data/braingle/braingle_Logic.csv\")\n",
    "mathdata = pd.read_csv(\"data/braingle/braingle_Math.csv\")\n",
    "for index, row in logicdata.iterrows():\n",
    "    logicdifficulty[index] = row[\"Difficulty\"]\n",
    "    logicpopularity[index] = row[\"Popularity/Fun\"]\n",
    "    logiccategory[index] = row['Problem type [IN PROGRESS]']\n",
    "for index, row in mathdata.iterrows():\n",
    "    mathdifficulty[index] = row[\"Difficulty\"]\n",
    "    mathpopularity[index] = row[\"Popularity/Fun\"]\n",
    "    # mathcategory[index] = row['Problem type [IN PROGRESS]']\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    file_path = f\"response_evaluation/Math/MathAll-{model}/resultsEvaluations_evaluatedbyo3-2025-04-16.jsonl\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            alldata[(model, \"Math\")] = [json.loads(line) for line in file]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for model in models:\n",
    "    file_path = f\"response_evaluation/Logic/LogicAll-{model}/resultsEvaluations_evaluatedbyo3-2025-04-16.jsonl\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            alldata[(model, \"Logic\")] = [json.loads(line) for line in file]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "# for i in range(250):\n",
    "#     humanbruteforcemath[i] = round(humanbruteforcemath[i] / humanbruteforcetotalmath[i])\n",
    "#     humanbruteforcelogic[i] = round(humanbruteforcelogic[i] / humanbruteforcetotallogic[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d03c56aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DSChat, Test: Math, Prompt: basicprompt [ 9.6 31.2  3.6 55.6] 250.0 Correctness: 0.58/0.46\n",
      "Model: DSChat, Test: Math, Prompt: mathPrompt [10.  28.4  3.2 58.4] 250.0 Correctness: 0.556/0.38\n",
      "Model: DSChat, Test: Math, Prompt: hintPrompt [10.  28.   3.2 58.8] 250.0 Correctness: 0.56/0.36\n",
      "Model: DSChat, Test: Math, Prompt: combinedhintPrompt [10.4 25.2  2.8 61.6] 250.0 Correctness: 0.588/0.36\n",
      "Model: DSChat, Test: Logic, Prompt: basicprompt [ 6.4 32.4  3.6 57.6] 250.0 Correctness: 0.378/0.306\n",
      "Model: DSChat, Test: Logic, Prompt: mathPrompt [ 6.4 33.6  3.6 56.4] 250.0 Correctness: 0.408/0.28\n",
      "Model: DSChat, Test: Logic, Prompt: hintPrompt [ 7.2 27.6  2.8 62.4] 250.0 Correctness: 0.416/0.22\n",
      "Model: DSChat, Test: Logic, Prompt: combinedhintPrompt [ 6. 26.  4. 64.] 250.0 Correctness: 0.414/0.245\n",
      "Model: DSReason, Test: Math, Prompt: basicprompt [ 6.  14.   7.2 72.8] 250.0 Correctness: 0.668/0.48\n",
      "Model: DSReason, Test: Math, Prompt: mathPrompt [ 7.6 10.   5.6 76.7] 249.0 Correctness: 0.702/0.54\n",
      "Model: DSReason, Test: Math, Prompt: hintPrompt [ 7.2 14.   6.  72.8] 250.0 Correctness: 0.724/0.48\n",
      "Model: DSReason, Test: Math, Prompt: combinedhintPrompt [ 6.4  8.   6.8 78.8] 250.0 Correctness: 0.728/0.56\n",
      "Model: DSReason, Test: Logic, Prompt: basicprompt [ 2.8 13.7  6.8 76.7] 249.0 Correctness: 0.446/0.26\n",
      "Model: DSReason, Test: Logic, Prompt: mathPrompt [ 2.4 12.4  7.6 77.6] 250.0 Correctness: 0.454/0.32\n",
      "Model: DSReason, Test: Logic, Prompt: hintPrompt [ 3.6  9.6  6.  80.7] 249.0 Correctness: 0.494/0.327\n",
      "Model: DSReason, Test: Logic, Prompt: combinedhintPrompt [ 4.   8.8  5.6 81.5] 249.0 Correctness: 0.506/0.4\n",
      "Model: GeminiFlash, Test: Math, Prompt: basicprompt [13. 21.  4. 62.] 100.0 Correctness: 0.54/0.395\n",
      "Model: o3, Test: Math, Prompt: basicprompt [ 3.9  9.2  8.6 78.3] 152.0 Correctness: 0.882/0.8\n",
      "Model: o3Batch, Test: Math, Prompt: basicprompt [ 0.   0.  12.5 87.5] 8.0 Correctness: 0.75/0.75\n",
      "Model: Qwen1, Test: Math, Prompt: basicprompt [ 9.6 26.8  3.6 60. ] 250.0 Correctness: 0.172/0.14\n",
      "Model: Qwen1, Test: Math, Prompt: mathPrompt [ 8.4 27.2  4.8 59.6] 250.0 Correctness: 0.164/0.1\n",
      "Model: Qwen1, Test: Math, Prompt: hintPrompt [ 8.8 29.6  4.4 57.2] 250.0 Correctness: 0.152/0.08\n",
      "Model: Qwen1, Test: Math, Prompt: combinedhintPrompt [ 9.2 26.4  4.  60.4] 250.0 Correctness: 0.176/0.1\n",
      "Model: Qwen1, Test: Logic, Prompt: basicprompt [ 4.8 18.   5.2 72. ] 250.0 Correctness: 0.04/0.04\n",
      "Model: Qwen1, Test: Logic, Prompt: mathPrompt [ 5.6 20.   4.4 70. ] 250.0 Correctness: 0.04/0.06\n",
      "Model: Qwen1, Test: Logic, Prompt: hintPrompt [ 5.2 15.6  4.8 74.4] 250.0 Correctness: 0.068/0.06\n",
      "Model: Qwen1, Test: Logic, Prompt: combinedhintPrompt [ 6.8 20.   3.2 70. ] 250.0 Correctness: 0.036/0.041\n",
      "Model: Qwen14, Test: Math, Prompt: basicprompt [10.  27.6  3.2 59.2] 250.0 Correctness: 0.412/0.22\n",
      "Model: Qwen14, Test: Math, Prompt: mathPrompt [ 8.4 25.6  4.8 61.2] 250.0 Correctness: 0.44/0.3\n",
      "Model: Qwen14, Test: Math, Prompt: hintPrompt [10.4 27.6  2.8 59.2] 250.0 Correctness: 0.44/0.2\n",
      "Model: Qwen14, Test: Math, Prompt: combinedhintPrompt [10.  27.6  3.2 59.2] 250.0 Correctness: 0.426/0.26\n",
      "Model: Qwen14, Test: Logic, Prompt: basicprompt [ 6.8 30.8  3.2 59.2] 250.0 Correctness: 0.22/0.16\n",
      "Model: Qwen14, Test: Logic, Prompt: mathPrompt [ 6.  31.2  4.  58.8] 250.0 Correctness: 0.236/0.16\n",
      "Model: Qwen14, Test: Logic, Prompt: hintPrompt [ 6.8 30.4  3.2 59.6] 250.0 Correctness: 0.272/0.22\n",
      "Model: Qwen14, Test: Logic, Prompt: combinedhintPrompt [ 5.2 32.   4.8 58. ] 250.0 Correctness: 0.26/0.32\n",
      "Model: Qwen70, Test: Math, Prompt: basicprompt [ 9.2 24.4  4.  62.4] 250.0 Correctness: 0.424/0.2\n",
      "Model: Qwen70, Test: Math, Prompt: mathPrompt [ 8.4 24.4  4.8 62.4] 250.0 Correctness: 0.408/0.22\n",
      "Model: Qwen70, Test: Math, Prompt: hintPrompt [ 8.  20.4  5.2 66.4] 250.0 Correctness: 0.456/0.24\n",
      "Model: Qwen70, Test: Math, Prompt: combinedhintPrompt [ 8.4 24.   4.8 62.8] 250.0 Correctness: 0.442/0.18\n",
      "Model: Qwen70, Test: Logic, Prompt: basicprompt [ 7.2 23.2  2.8 66.8] 250.0 Correctness: 0.244/0.16\n",
      "Model: Qwen70, Test: Logic, Prompt: mathPrompt [ 6.  24.4  4.  65.6] 250.0 Correctness: 0.244/0.14\n",
      "Model: Qwen70, Test: Logic, Prompt: hintPrompt [ 7.2 25.2  2.8 64.8] 250.0 Correctness: 0.26/0.2\n",
      "Model: Qwen70, Test: Logic, Prompt: combinedhintPrompt [ 6.  19.6  4.  70.4] 250.0 Correctness: 0.292/0.26\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    for test in tests:\n",
    "        try:\n",
    "            data = pd.DataFrame(alldata[(model, test)])\n",
    "        except:\n",
    "            continue\n",
    "        prompts = data[\"PromptType\"].unique()\n",
    "\n",
    "        for prompt in prompts:\n",
    "            # if \"hint\" in prompt and \"Main\" in test or \"symbol\" in prompt:\n",
    "            #     continue\n",
    "            tempdata = data[data[\"PromptType\"]==prompt]\n",
    "            bfarray = np.zeros((2, 2))\n",
    "            bfdiff = []\n",
    "            nbfdiff = []\n",
    "            bfpop = []\n",
    "            nbfpop = []\n",
    "            correctness = []\n",
    "            correctnessDiff = []\n",
    "            category = {}\n",
    "            count = 0\n",
    "\n",
    "            for index, row in tempdata.iterrows():\n",
    "                # if (type(row[\"Response\"]) != str):\n",
    "                #     print(row[\"Response\"])\n",
    "                if (type(row[\"Response\"]) != str or row[\"Response\"] == None or row[\"Response\"] == \"NaN\" or row[\"Response\"] == \"None\" or row[\"Response\"] == \"\" or row[\"model_bruteforce\"] == \"NULL\" or row[\"Response\"] is str and row[\"Response\"].isspace()):\n",
    "                    # print(\"Filtered!\")\n",
    "                    continue\n",
    "                try:\n",
    "                    if (row[\"model_bruteforce\"] == \"1\"):\n",
    "                        if \"Math\" in test:\n",
    "                            bfdiff.append(mathdifficulty[row[\"ID\"]])\n",
    "                            bfpop.append(mathpopularity[row[\"ID\"]])\n",
    "                        else:\n",
    "                            bfdiff.append(logicdifficulty[row[\"ID\"]])\n",
    "                            bfpop.append(logicpopularity[row[\"ID\"]])\n",
    "                    elif (row[\"model_bruteforce\"] == \"0\"):\n",
    "                        if \"Math\" in test:\n",
    "                            nbfdiff.append(mathdifficulty[row[\"ID\"]])\n",
    "                            nbfpop.append(mathpopularity[row[\"ID\"]])\n",
    "                        else:\n",
    "                            nbfdiff.append(logicdifficulty[row[\"ID\"]])\n",
    "                            nbfpop.append(logicpopularity[row[\"ID\"]])\n",
    "                    \n",
    "                    if \"Math\" in test:\n",
    "                        bfarray[1-int(row[\"model_bruteforce\"])][1-humanbruteforcemath[row['ID']]] += 1\n",
    "                    if \"Logic\" in test:\n",
    "                        bfarray[1-int(row[\"model_bruteforce\"])][1-humanbruteforcelogic[row['ID']]] += 1\n",
    "                    correctness.append(int(row[\"correctness\"]))\n",
    "\n",
    "                    if \"Logic\" in test:\n",
    "                        # print(logiccategory[row[\"ID\"]])\n",
    "                        if logiccategory[row[\"ID\"]] not in category.keys():\n",
    "                            category[logiccategory[row[\"ID\"]]] = [0, 0]\n",
    "                        \n",
    "                        # print(row[\"model_bruteforce\"])\n",
    "\n",
    "                        category[logiccategory[row[\"ID\"]]][1-int(row[\"model_bruteforce\"])] += 1\n",
    "\n",
    "                    if (row['ID'] < 50):\n",
    "                        correctnessDiff.append(int(row[\"correctness\"]))\n",
    "                    # count += 1\n",
    "\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    # print(\"Error:\", e)\n",
    "                    # print(row[\"model_bruteforce\"])\n",
    "                    pass\n",
    "            # print(category)\n",
    "            \n",
    "            print(f\"Model: {model}, Test: {test}, Prompt: {prompt}\", \n",
    "                #   print(category),\n",
    "                  np.round(100*bfarray.flatten()/np.sum(bfarray), 1), np.sum(bfarray), \n",
    "                  \"Correctness:\", str(np.round(np.mean(correctness), 3)) + \"/\" + str(np.round(np.mean(correctnessDiff), 3)), \n",
    "                #   \"Difficulty (BF/NBF):\", np.round(np.mean(bfdiff), 2), np.round(np.mean(nbfdiff), 2), \n",
    "                #   \"Popularity (BF/NBF):\", np.round(np.mean(bfpop), 2), np.round(np.mean(nbfpop), 2),\n",
    "                  \n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5ed10e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human Solution Math:\n",
      "Difficulty (BF/NBF): 2.83 2.8\n",
      "Popularity (BF/NBF): 2.32 2.33\n",
      "Human Solution Logic:\n",
      "Difficulty (BF/NBF): 2.7 2.65\n",
      "Popularity (BF/NBF): 2.37 2.51\n"
     ]
    }
   ],
   "source": [
    "print(\"Human Solution Math:\")\n",
    "totaldiffbf = []\n",
    "totaldiffnbf = []\n",
    "totalpopbf = []\n",
    "totalpopnbf = []\n",
    "for i in range(250):\n",
    "    if (humanbruteforcemath[i] == 1):\n",
    "        totaldiffbf.append(mathdifficulty[i])\n",
    "        totalpopbf.append(mathpopularity[i])\n",
    "    else:\n",
    "        totaldiffnbf.append(mathdifficulty[i])\n",
    "        totalpopnbf.append(mathpopularity[i])\n",
    "print(\"Difficulty (BF/NBF):\", np.round(np.mean(totaldiffbf), 2), np.round(np.mean(totaldiffnbf), 2))\n",
    "print(\"Popularity (BF/NBF):\", np.round(np.mean(totalpopbf), 2), np.round(np.mean(totalpopnbf), 2))\n",
    "print(\"Human Solution Logic:\")\n",
    "totaldiffbf = []\n",
    "totaldiffnbf = []\n",
    "totalpopbf = []\n",
    "totalpopnbf = []\n",
    "for i in range(250):\n",
    "    if (humanbruteforcelogic[i] == 1):\n",
    "        totaldiffbf.append(logicdifficulty[i])\n",
    "        totalpopbf.append(logicpopularity[i])\n",
    "    else:\n",
    "        totaldiffnbf.append(logicdifficulty[i])\n",
    "        totalpopnbf.append(logicpopularity[i])\n",
    "print(\"Difficulty (BF/NBF):\", np.round(np.mean(totaldiffbf), 2), np.round(np.mean(totaldiffnbf), 2))\n",
    "print(\"Popularity (BF/NBF):\", np.round(np.mean(totalpopbf), 2), np.round(np.mean(totalpopnbf), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c912abea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Brainteasers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
